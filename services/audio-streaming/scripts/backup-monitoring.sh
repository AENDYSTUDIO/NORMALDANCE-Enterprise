#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: ./backup-monitoring.sh [options]

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR)"
BACKUP_DIR="/opt/backups/monitoring"
BACKUP_TYPE="full"
RETENTION_DAYS=30
COMPRESS=true
ENCRYPT=false
S3_BUCKET=""
REMOTE_DEST=""
NOTIFY_EMAIL=""
SLACK_WEBHOOK=""
EXCLUDE_DATA=false
EXCLUDE_IMAGES=false
EXCLUDE_CONFIG=false

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
while [[ $# -gt 0 ]]; do
    case $1 in
        --type|-t)
            BACKUP_TYPE="$2"
            shift 2
            ;;
        --retention|-r)
            RETENTION_DAYS="$2"
            shift 2
            ;;
        --compress|-c)
            COMPRESS=true
            shift
            ;;
        --no-compress)
            COMPRESS=false
            shift
            ;;
        --encrypt|-e)
            ENCRYPT=true
            shift
            ;;
        --s3-bucket|-s)
            S3_BUCKET="$2"
            shift 2
            ;;
        --remote|-R)
            REMOTE_DEST="$2"
            shift 2
            ;;
        --email|-m)
            NOTIFY_EMAIL="$2"
            shift 2
            ;;
        --slack|-w)
            SLACK_WEBHOOK="$2"
            shift 2
            ;;
        --exclude-data)
            EXCLUDE_DATA=true
            shift
            ;;
        --exclude-images)
            EXCLUDE_IMAGES=true
            shift
            ;;
        --exclude-config)
            EXCLUDE_CONFIG=true
            shift
            ;;
        --help|-h)
            show_help
            exit 0
            ;;
        *)
            error "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç: $1"
            exit 1
            ;;
    esac
done

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}" >&2
}

warning() {
    echo -e "${YELLOW}[WARNING] $1${NC}"
}

success() {
    echo -e "${GREEN}[SUCCESS] $1${NC}"
}

info() {
    echo -e "${BLUE}[INFO] $1${NC}"
}

# –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
show_help() {
    cat <<EOF
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 [options]

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    --type, -t        –¢–∏–ø –±—ç–∫–∞–ø–∞: full, config, data, images (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: full)
    --retention, -r   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–µ–Ω–∏—è –±—ç–∫–∞–ø–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30)
    --compress, -c    –°–∂–∞—Ç–∏–µ –±—ç–∫–∞–ø–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤–∫–ª—é—á–µ–Ω–æ)
    --no-compress     –û—Ç–∫–ª—é—á–∏—Ç—å —Å–∂–∞—Ç–∏–µ
    --encrypt, -e     –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞
    --s3-bucket, -s   S3 bucket –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –±—ç–∫–∞–ø–æ–≤
    --remote, -R      –£–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è (user@host:/path)
    --email, -m       Email –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    --slack, -w       Slack webhook –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    --exclude-data    –ò—Å–∫–ª—é—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ Prometheus/Grafana
    --exclude-images  –ò—Å–∫–ª—é—á–∏—Ç—å Docker –æ–±—Ä–∞–∑—ã
    --exclude-config  –ò—Å–∫–ª—é—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    --help, -h        –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É

–ü—Ä–∏–º–µ—Ä—ã:
    $0 --type config --s3-bucket my-backups
    $0 --type data --remote user@backup-server:/backups/monitoring
    $0 --encrypt --email admin@example.com
EOF
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
check_dependencies() {
    local deps=("docker" "docker-compose" "tar" "gzip" "jq")
    local missing_deps=()
    
    for dep in "${deps[@]}"; do
        if ! command -v "$dep" &> /dev/null; then
            missing_deps+=("$dep")
        fi
    done
    
    if [ ${#missing_deps[@]} -gt 0 ]; then
        error "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: ${missing_deps[*]}"
        exit 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ AWS CLI –¥–ª—è S3
    if [ -n "$S3_BUCKET" ] && ! command -v aws &> /dev/null; then
        error "AWS CLI —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è S3 –±—ç–∫–∞–ø–æ–≤"
        exit 1
    fi
}

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –±—ç–∫–∞–ø–æ–≤
create_backup_dir() {
    local dir="$BACKUP_DIR/$BACKUP_TYPE"
    
    if [ ! -d "$dir" ]; then
        mkdir -p "$dir"
        log "–°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –±—ç–∫–∞–ø–æ–≤: $dir"
    fi
    
    echo "$dir"
}

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –±—ç–∫–∞–ø–∞
generate_backup_filename() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local filename="backup_${timestamp}"
    
    case "$BACKUP_TYPE" in
        "full")
            filename="${filename}_full"
            ;;
        "config")
            filename="${filename}_config"
            ;;
        "data")
            filename="${filename}_data"
            ;;
        "images")
            filename="${filename}_images"
            ;;
    esac
    
    if [ "$COMPRESS" = true ]; then
        filename="${filename}.tar.gz"
    else
        filename="${filename}.tar"
    fi
    
    echo "$filename"
}

# –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–∞
create_metadata() {
    local backup_dir=$1
    local backup_file=$2
    
    local metadata_file="$backup_dir/metadata.json"
    
    cat > "$metadata_file" <<EOF
{
    "backup_type": "$BACKUP_TYPE",
    "date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "hostname": "$(hostname)",
    "backup_file": "$(basename "$backup_file")",
    "compressed": $COMPRESS,
    "encrypted": $ENCRYPT,
    "exclude_data": $EXCLUDE_DATA,
    "exclude_images": $EXCLUDE_IMAGES,
    "exclude_config": $EXCLUDE_CONFIG,
    "docker_images": $(docker images --format '{{json .}}' | jq -s '.'),
    "container_status": $(docker ps --format '{{json .}}' | jq -s '.'),
    "backup_size": $(stat -c%s "$backup_file" 2>/dev/null || echo 0)
}
EOF
    
    log "–°–æ–∑–¥–∞–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±—ç–∫–∞–ø–∞"
}

# –ë—ç–∫–∞–ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
backup_configuration() {
    local backup_dir=$1
    
    log "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏..."
    
    # Prometheus –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    if [ -d "$PROJECT_DIR/prometheus" ]; then
        cp -r "$PROJECT_DIR/prometheus" "$backup_dir/"
    fi
    
    # Grafana –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    if [ -d "$PROJECT_DIR/grafana" ]; then
        cp -r "$PROJECT_DIR/grafana" "$backup_dir/"
    fi
    
    # Docker Compose
    if [ -f "$PROJECT_DIR/docker-compose.monitoring.yml" ]; then
        cp "$PROJECT_DIR/docker-compose.monitoring.yml" "$backup_dir/docker-compose.yml"
    fi
    
    # Environment —Ñ–∞–π–ª—ã
    if [ -f "$PROJECT_DIR/.env" ]; then
        cp "$PROJECT_DIR/.env" "$backup_dir/"
    fi
    
    # Nginx –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    if [ -d "$PROJECT_DIR/nginx" ]; then
        cp -r "$PROJECT_DIR/nginx" "$backup_dir/"
    fi
    
    # Alertmanager –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    if [ -d "$PROJECT_DIR/alertmanager" ]; then
        cp -r "$PROJECT_DIR/alertmanager" "$backup_dir/"
    fi
}

# –ë—ç–∫–∞–ø –¥–∞–Ω–Ω—ã—Ö
backup_data() {
    local backup_dir=$1
    
    log "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –¥–∞–Ω–Ω—ã—Ö..."
    
    # Prometheus –¥–∞–Ω–Ω—ã–µ
    local prometheus_volume=$(docker volume inspect monitoring_prometheus_data 2>/dev/null | jq -r '.[0].Mountpoint')
    if [ -n "$prometheus_volume" ] && [ "$prometheus_volume" != "null" ]; then
        mkdir -p "$backup_dir/prometheus_data"
        cp -r "$prometheus_volume"/* "$backup_dir/prometheus_data/" 2>/dev/null || true
    fi
    
    # Grafana –¥–∞–Ω–Ω—ã–µ
    local grafana_volume=$(docker volume inspect monitoring_grafana_data 2>/dev/null | jq -r '.[0].Mountpoint')
    if [ -n "$grafana_volume" ] && [ "$grafana_volume" != "null" ]; then
        mkdir -p "$backup_dir/grafana_data"
        cp -r "$grafana_volume"/* "$backup_dir/grafana_data/" 2>/dev/null || true
    fi
    
    # Redis –¥–∞–Ω–Ω—ã–µ
    local redis_volume=$(docker volume inspect monitoring_redis_data 2>/dev/null | jq -r '.[0].Mountpoint')
    if [ -n "$redis_volume" ] && [ "$redis_volume" != "null" ]; then
        mkdir -p "$backup_dir/redis_data"
        cp -r "$redis_volume"/* "$backup_dir/redis_data/" 2>/dev/null || true
    fi
}

# –ë—ç–∫–∞–ø Docker –æ–±—Ä–∞–∑–æ–≤
backup_docker_images() {
    local backup_dir=$1
    
    log "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ Docker –æ–±—Ä–∞–∑–æ–≤..."
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –æ–±—Ä–∞–∑–æ–≤
    local images=$(docker images --format '{{.Repository}}:{{.Tag}}' | grep -E 'prometheus|grafana|alertmanager|redis|nginx')
    
    if [ -n "$images" ]; then
        docker save $images -o "$backup_dir/docker_images.tar"
        log "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ $(echo "$images" | wc -l) Docker –æ–±—Ä–∞–∑–æ–≤"
    else
        warning "Docker –æ–±—Ä–∞–∑—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    fi
}

# –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞
create_archive() {
    local backup_dir=$1
    local backup_file=$2
    
    log "–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞..."
    
    local archive_name=$(basename "$backup_file" .tar.gz)
    archive_name=$(basename "$archive_name" .tar)
    
    cd "$backup_dir"
    
    if [ "$COMPRESS" = true ]; then
        tar -czf "$backup_file" --exclude="*.tar.gz" .
    else
        tar -cf "$backup_file" --exclude="*.tar" .
    fi
    
    log "–ê—Ä—Ö–∏–≤ —Å–æ–∑–¥–∞–Ω: $backup_file"
}

# –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞
encrypt_backup() {
    local backup_file=$1
    
    if [ "$ENCRYPT" = false ]; then
        return
    fi
    
    log "–®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞..."
    
    read -s -p "–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è: " password
    echo
    
    openssl enc -aes-256-cbc -salt -in "$backup_file" -out "${backup_file}.enc" -k "$password"
    
    if [ $? -eq 0 ]; then
        rm "$backup_file"
        mv "${backup_file}.enc" "$backup_file"
        log "–ë—ç–∫–∞–ø –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω"
    else
        error "–û—à–∏–±–∫–∞ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è"
        exit 1
    fi
}

# –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ S3
upload_to_s3() {
    local backup_file=$1
    
    if [ -z "$S3_BUCKET" ]; then
        return
    fi
    
    log "–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ S3..."
    
    aws s3 cp "$backup_file" "s3://$S3_BUCKET/monitoring/$(basename "$backup_file")"
    
    if [ $? -eq 0 ]; then
        log "–ë—ç–∫–∞–ø –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ S3"
    else
        error "–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ S3"
    fi
}

# –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
upload_to_remote() {
    local backup_file=$1
    
    if [ -z "$REMOTE_DEST" ]; then
        return
    fi
    
    log "–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä..."
    
    if [[ "$REMOTE_DEST" == *"@"* ]]; then
        # SCP
        scp "$backup_file" "$REMOTE_DEST"
    else
        # Rsync
        rsync -avz "$backup_file" "$REMOTE_DEST"
    fi
    
    if [ $? -eq 0 ]; then
        log "–ë—ç–∫–∞–ø –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä"
    else
        error "–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä"
    fi
}

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
cleanup_old_backups() {
    log "–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤..."
    
    find "$BACKUP_DIR" -name "backup_*.tar*" -type f -mtime +$RETENTION_DAYS -delete
    
    if [ -n "$S3_BUCKET" ]; then
        aws s3 ls "s3://$S3_BUCKET/monitoring/" | \
            awk '{print $4}' | \
            while read -r file; do
                local file_date=$(echo "$file" | grep -o '[0-9]\{8\}' | head -1)
                local file_age=$(( ($(date +%s) - $(date -d "$file_date" +%s)) / 86400 ))
                
                if [ $file_age -gt $RETENTION_DAYS ]; then
                    aws s3 rm "s3://$S3_BUCKET/monitoring/$file"
                fi
            done
    fi
    
    log "–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞"
}

# –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
send_notifications() {
    local status=$1
    local message=$2
    local backup_file=$3
    
    local backup_size=$(stat -c%s "$backup_file" 2>/dev/null || echo 0)
    local backup_size_mb=$((backup_size / 1024 / 1024))
    
    # JSON payload
    local payload=$(cat <<EOF
{
    "text": "üìä Monitoring Backup $status",
    "attachments": [
        {
            "color": "$([ "$status" = "SUCCESS" ] && echo "good" || echo "danger")",
            "fields": [
                {
                    "title": "Status",
                    "value": "$status",
                    "short": true
                },
                {
                    "title": "Type",
                    "value": "$BACKUP_TYPE",
                    "short": true
                },
                {
                    "title": "Message",
                    "value": "$message",
                    "short": false
                },
                {
                    "title": "Size",
                    "value": "${backup_size_mb}MB",
                    "short": true
                },
                {
                    "title": "File",
                    "value": "$(basename "$backup_file")",
                    "short": true
                },
                {
                    "title": "Timestamp",
                    "value": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
                    "short": true
                }
            ]
        }
    ]
}
EOF
)
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "$payload" \
            "$SLACK_WEBHOOK" > /dev/null 2>&1 || true
    fi
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ email
    if [ -n "$NOTIFY_EMAIL" ]; then
        local subject="Monitoring Backup - $status"
        local body=$(cat <<EOF
Backup completed:
- Type: $BACKUP_TYPE
- Status: $status
- File: $(basename "$backup_file")
- Size: ${backup_size_mb}MB
- Timestamp: $(date)
- Message: $message
EOF
)
        
        echo "$body" | mail -s "$subject" "$NOTIFY_EMAIL" 2>/dev/null || true
    fi
}

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞
create_backup() {
    local start_time=$(date +%s)
    
    log "–ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞..."
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    check_dependencies
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    local backup_dir=$(create_backup_dir)
    local backup_filename=$(generate_backup_filename)
    local backup_file="$backup_dir/$backup_filename"
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    local temp_dir=$(mktemp -d)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
    case "$BACKUP_TYPE" in
        "config")
            backup_configuration "$temp_dir"
            ;;
        "data")
            backup_data "$temp_dir"
            ;;
        "images")
            backup_docker_images "$temp_dir"
            ;;
        "full")
            backup_configuration "$temp_dir"
            [ "$EXCLUDE_DATA" = false ] && backup_data "$temp_dir"
            [ "$EXCLUDE_IMAGES" = false ] && backup_docker_images "$temp_dir"
            ;;
        *)
            error "‚úó –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –±—ç–∫–∞–ø–∞: $BACKUP_TYPE"
            exit 1
            ;;
    esac
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞
    create_archive "$temp_dir" "$backup_file"
    
    # –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
    encrypt_backup "$backup_file"
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    create_metadata "$backup_dir" "$backup_file"
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞
    upload_to_s3 "$backup_file"
    upload_to_remote "$backup_file"
    
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    rm -rf "$temp_dir"
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
    cleanup_old_backups
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    success "–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ: $backup_filename"
    log "–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: ${duration} —Å–µ–∫—É–Ω–¥"
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    send_notifications "SUCCESS" "–ë—ç–∫–∞–ø —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω" "$backup_file"
}

# –ó–∞–ø—É—Å–∫
create_backup